{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_6DGm7QazYH"
      },
      "outputs": [],
      "source": [
        "# Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from category_encoders import WOEEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.utils import resample\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import warnings\n",
        "\n",
        "warnings.simplefilter(\"ignore\")\n",
        "\n",
        "# Load Data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "file_path_train = '/content/drive/My Drive/Colab/fraudTrain.csv'\n",
        "file_path_test = '/content/drive/My Drive/Colab/fraudTest.csv'\n",
        "df_train = pd.read_csv(file_path_train, index_col='Unnamed: 0')\n",
        "df_test = pd.read_csv(file_path_test, index_col='Unnamed: 0')\n",
        "\n",
        "# Exploratory Data Analysis\n",
        "df_train.head(3)\n",
        "df_train.info()\n",
        "df_train.shape\n",
        "df_train[\"is_fraud\"].value_counts()\n",
        "df_train.isna().sum().sum()\n",
        "df_train.duplicated().sum()\n",
        "\n",
        "fig, axes = plt.subplots(ncols=2, nrows=1, figsize=(15, 8))\n",
        "df_train.groupby('gender')['is_fraud'].count().plot.pie(explode=[0.1, 0.1], autopct=\"%1.1f%%\", ax=axes[0])\n",
        "sns.countplot(x=\"gender\", hue=\"is_fraud\", data=df_train, ax=axes[1])\n",
        "for p in axes[1].patches:\n",
        "    axes[1].annotate(f'{p.get_height()}', (p.get_x() + p.get_width() / 2., p.get_height()),\n",
        "                     ha='center', va='center', xytext=(0, 10), textcoords='offset points')\n",
        "plt.show()\n",
        "\n",
        "df_train[\"is_fraud\"].value_counts().plot.pie(labels=[\"No\", \"Yes\"], autopct=\"%0.0f%%\", figsize=(10, 6))\n",
        "plt.title(\"is_fraud Counts\")\n",
        "plt.show()\n",
        "\n",
        "# Feature Engineering\n",
        "df_train['trans_date_trans_time'] = pd.to_datetime(df_train['trans_date_trans_time'], format='mixed')\n",
        "df_test['trans_date_trans_time'] = pd.to_datetime(df_test['trans_date_trans_time'], format='mixed')\n",
        "df_train['hour'] = df_train['trans_date_trans_time'].dt.hour\n",
        "df_test['hour'] = df_test['trans_date_trans_time'].dt.hour\n",
        "df_train['month'] = df_train['trans_date_trans_time'].dt.month\n",
        "df_test['month'] = df_test['trans_date_trans_time'].dt.month\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5), sharey=True)\n",
        "sns.histplot(x='hour', data=df_train[df_train[\"is_fraud\"] == 0], stat=\"density\", bins=24, ax=ax1, color=\"orange\")\n",
        "sns.histplot(x='hour', data=df_train[df_train[\"is_fraud\"] == 1], stat=\"density\", bins=24, ax=ax2, color=\"green\")\n",
        "ax1.set_title(\"Not Fraud\")\n",
        "ax2.set_title(\"Fraud\")\n",
        "ax1.set_xticks(np.arange(24))\n",
        "ax2.set_xticks(np.arange(24))\n",
        "plt.show()\n",
        "\n",
        "# Data Pre-processing\n",
        "df_train = df_train.drop(['first', 'unix_time', 'dob', 'cc_num', 'zip', 'city', 'street', 'state', 'trans_num', 'trans_date_trans_time'], axis=1)\n",
        "df_test = df_test.drop(['first', 'unix_time', 'dob', 'cc_num', 'zip', 'city', 'street', 'state', 'trans_num', 'trans_date_trans_time'], axis=1)\n",
        "df_train['merchant'] = df_train['merchant'].apply(lambda x: x.replace('fraud_', ''))\n",
        "\n",
        "# Data Encoding\n",
        "df_train['gender'] = df_train['gender'].map({'F': 0, 'M': 1})\n",
        "for col in ['job', 'merchant', 'category', 'lat', 'last']:\n",
        "    df_train[col] = WOEEncoder().fit_transform(df_train[col], df_train['is_fraud'])\n",
        "\n",
        "# Down-Sampling and Scaling\n",
        "major_class = df_train[df_train[\"is_fraud\"] == 0]\n",
        "minor_class = df_train[df_train[\"is_fraud\"] == 1]\n",
        "major_class_downsampled = resample(major_class, replace=False, n_samples=len(minor_class))\n",
        "balanced_df = pd.concat([minor_class, major_class_downsampled], axis=0)\n",
        "X = balanced_df.drop(\"is_fraud\", axis=1)\n",
        "y = balanced_df[\"is_fraud\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=65)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Machine Learning Model Training\n",
        "# Logistic Regression\n",
        "lr_model = LogisticRegression()\n",
        "lr_model.fit(X_train, y_train)\n",
        "lr_predictions = lr_model.predict(X_test)\n",
        "lr_accuracy = accuracy_score(y_test, lr_predictions)\n",
        "\n",
        "# Support Vector Machine\n",
        "svc_model = LinearSVC()\n",
        "svc_model.fit(X_train, y_train)\n",
        "svc_predictions = svc_model.predict(X_test)\n",
        "svc_accuracy = accuracy_score(y_test, svc_predictions)\n",
        "\n",
        "# Gaussian Naive Bayes\n",
        "gnb_model = GaussianNB()\n",
        "gnb_model.fit(X_train, y_train)\n",
        "gnb_predictions = gnb_model.predict(X_test)\n",
        "gnb_accuracy = accuracy_score(y_test, gnb_predictions)\n",
        "\n",
        "# Decision Tree\n",
        "dt_model = DecisionTreeClassifier(max_depth=1, random_state=0)\n",
        "dt_model.fit(X_train, y_train)\n",
        "dt_predictions = dt_model.predict(X_test)\n",
        "dt_accuracy = accuracy_score(y_test, dt_predictions)\n",
        "\n",
        "# Random Forest\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=0)\n",
        "rf_model.fit(X_train, y_train)\n",
        "rf_predictions = rf_model.predict(X_test)\n",
        "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
        "\n",
        "# XGBoost\n",
        "xgb_model = XGBClassifier(random_state=0)\n",
        "xgb_model.fit(X_train, y_train)\n",
        "xgb_predictions = xgb_model.predict(X_test)\n",
        "xgb_accuracy = accuracy_score(y_test, xgb_predictions)\n",
        "\n",
        "# Results Visualization\n",
        "algorithms = ['XGBClassifier', 'RandomForest', 'DecisionTree', 'LogisticRegression', 'SVM', 'GaussianNB']\n",
        "accuracies = [xgb_accuracy, rf_accuracy, dt_accuracy, lr_accuracy, svc_accuracy, gnb_accuracy]\n",
        "results_df = pd.DataFrame({'Algorithm': algorithms, 'Accuracy': accuracies})\n",
        "\n",
        "plt.figure(figsize=(7, 5))\n",
        "plt.bar(results_df['Algorithm'], results_df['Accuracy'], color='skyblue')\n",
        "plt.xlabel('Algorithm')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Accuracy of Different Algorithms')\n",
        "plt.ylim(0, 1)\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(axis='x')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ]
}